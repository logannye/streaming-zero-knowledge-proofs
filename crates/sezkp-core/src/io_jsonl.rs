//! JSON Lines (NDJSON) helpers for streaming `BlockSummary` I/O.
//!
//! These functions provide memory-efficient line-by-line reading/writing
//! suitable for very large inputs. Each line is a single JSON object.
//!
//! - **Reader**: returns an iterator that *owns* its underlying reader,
//!   yielding `Result<BlockSummary>` so callers can surface per-line errors.
//!   (No borrowed iterators that outlive their buffers.)
//! - **Writer**: uses `serde_json::to_writer` to avoid intermediate allocations.
//!
//! # Formats
//! We treat both `.jsonl` and `.ndjson` as equivalent line-delimited JSON.

#![allow(unused_imports)]
use anyhow::{Context, Result};
use serde::Serialize;
use std::fs::File;
use std::io::{BufRead, BufReader, BufWriter, Read, Write};
use std::path::Path;

use crate::BlockSummary;

/// Owning JSONL iterator over `BlockSummary`.
///
/// Holds the file and buffered reader internally to avoid lifetime pitfalls
/// of returning a borrowed `Lines<'_>` iterator.
pub struct JsonlBlockIter {
    rdr: BufReader<File>,
    buf: String,
    line_no: usize,
}

impl JsonlBlockIter {
    fn new(file: File) -> Self {
        Self {
            rdr: BufReader::new(file),
            buf: String::with_capacity(8 << 10),
            line_no: 0,
        }
    }
}

impl Iterator for JsonlBlockIter {
    type Item = Result<BlockSummary>;

    fn next(&mut self) -> Option<Self::Item> {
        self.buf.clear();
        match self.rdr.read_line(&mut self.buf) {
            Ok(0) => None, // EOF
            Ok(_) => {
                self.line_no += 1;
                // Trim a single trailing '\n' or '\r\n'
                if self.buf.ends_with('\n') {
                    self.buf.pop();
                    if self.buf.ends_with('\r') {
                        self.buf.pop();
                    }
                }
                if self.buf.is_empty() {
                    // Allow blank lines but surface them clearly as parse errors.
                    return Some(Err(anyhow::anyhow!(
                        "parse jsonl line {}: empty line",
                        self.line_no
                    )));
                }
                let parsed: Result<BlockSummary> = serde_json::from_str(&self.buf)
                    .with_context(|| format!("parse jsonl line {}", self.line_no));
                Some(parsed)
            }
            Err(e) => Some(Err(e).with_context(|| format!("read line {}", self.line_no + 1))),
        }
    }
}

/// Stream read: one JSON object per line â†’ yields `BlockSummary` items.
///
/// This is resilient to large inputs: we only materialize one block at a time.
/// Each line is parsed independently; the iterator yields `Err` with a line
/// number if parsing fails.
///
/// # Errors
/// Opening the file may fail. Individual iteration items may be `Err` if a
/// particular line is malformed.
pub fn stream_block_summaries_jsonl<P: AsRef<Path>>(path: P) -> Result<JsonlBlockIter> {
    let f = File::open(path.as_ref())
        .with_context(|| format!("open {}", path.as_ref().display()))?;
    Ok(JsonlBlockIter::new(f))
}

/// Write blocks as JSON Lines (one object per line).
///
/// Uses `serde_json::to_writer` directly to avoid temporary `String`s.
pub fn write_block_summaries_jsonl<P: AsRef<Path>>(
    path: P,
    blocks: &[BlockSummary],
) -> Result<()> {
    let f = File::create(path.as_ref())
        .with_context(|| format!("create {}", path.as_ref().display()))?;
    let mut w = BufWriter::new(f);
    for b in blocks {
        serde_json::to_writer(&mut w, b).context("serialize block to json")?;
        w.write_all(b"\n").context("write newline")?;
    }
    w.flush().context("flush writer")?;
    Ok(())
}

/// Generic JSONL writer (handy if you want to dump other streams later).
pub fn write_jsonl<P: AsRef<Path>, T: Serialize>(path: P, items: &[T]) -> Result<()> {
    let f = File::create(path.as_ref())
        .with_context(|| format!("create {}", path.as_ref().display()))?;
    let mut w = BufWriter::new(f);
    for it in items {
        serde_json::to_writer(&mut w, it).context("serialize jsonl item")?;
        w.write_all(b"\n").context("write newline")?;
    }
    w.flush().context("flush writer")?;
    Ok(())
}

#[cfg(test)]
mod tests {
    use super::*;
    use serde::{Deserialize, Serialize};
    use std::io::Write as _;

    // Minimal surrogate to avoid depending on the real BlockSummary layout here.
    #[derive(Debug, Serialize, Deserialize, PartialEq)]
    struct Mini {
        k: u32,
    }

    #[test]
    fn jsonl_iterator_streams() {
        // Write a tiny temp file with two lines.
        let mut p = std::env::temp_dir();
        p.push(format!("sezkp_core_jsonl_{}.jsonl", rand_suffix()));
        {
            let mut f = File::create(&p).unwrap();
            writeln!(f, r#"{{"k":1}}"#).unwrap();
            writeln!(f, r#"{{"k":2}}"#).unwrap();
        }

        // Read via owning iterator; convert to Mini through serde roundtrip using the same parser.
        let it = stream_block_summaries_jsonl(&p).unwrap();
        // We cannot parse into Mini here because Item is BlockSummary; this test asserts iterator ownership by consuming bytes.
        // Smoke: advance the iterator to ensure no lifetime issues arise.
        drop(it);
        let _ = std::fs::remove_file(p);
    }

    fn rand_suffix() -> u64 {
        use std::time::{SystemTime, UNIX_EPOCH};
        SystemTime::now()
            .duration_since(UNIX_EPOCH)
            .unwrap()
            .as_nanos() as u64
    }
}
